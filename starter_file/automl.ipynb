{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated ML\n",
        "\n",
        "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Experiment\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from azureml.widgets import RunDetails\n",
        "from azureml.train.hyperdrive.run import PrimaryMetricGoal\n",
        "import os\n",
        "import joblib\n",
        "from azureml.core.dataset import Dataset\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.core.model import Model\n",
        "from azureml.core.webservice import AciWebservice\n",
        "from azureml.core.environment import Environment\n",
        "from azureml.core.model import InferenceConfig\n",
        "import requests\n",
        "import json\n",
        "import sklearn\n",
        "from azureml.automl.runtime.onnx_convert import OnnxConverter\n",
        "import pandas as pd\n",
        "from pandas import DataFrame"
      ],
      "outputs": [],
      "execution_count": 36,
      "metadata": {
        "gather": {
          "logged": 1610484580235
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "### Overview\n",
        "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
        "\n",
        "\n",
        "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.from_config()\n",
        "\n",
        "# choose a name for experiment\n",
        "experiment_name = 'Heart-Disease-Predection'\n",
        "\n",
        "experiment=Experiment(ws, experiment_name)"
      ],
      "outputs": [],
      "execution_count": 37,
      "metadata": {
        "gather": {
          "logged": 1610484586222
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Compute\n",
        "from azureml.core.compute import ComputeTarget, AmlCompute\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "#Create compute cluster\n",
        "\n",
        "\n",
        "# choose a name for your cluster\n",
        "cluster_name= \"cpu-cluster\"\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws , name=cluster_name)\n",
        "    print('Found existing compute target')\n",
        "except ComputeTargetException:\n",
        "    print('Creating a new compute target ...')\n",
        "    compute_config = AmlCompute.provisioning_configuration(vm_size='Standard_D2_V2' , max_nodes=4)\n",
        "    #create the cluster\n",
        "    cpu_cluster=ComputeTarget.create(ws,cluster_name,compute_config)\n",
        "    print('cpu-cluster has been created')\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing compute target\n"
          ]
        }
      ],
      "execution_count": 38,
      "metadata": {
        "gather": {
          "logged": 1610484589556
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Try to load the dataset from the Workspace. Otherwise, create it from the file\r\n",
        "# NOTE: update the key to match the dataset name\r\n",
        "found = False\r\n",
        "key = \"Heart Failure Dataset\"\r\n",
        "\r\n",
        "if key in ws.datasets.keys(): \r\n",
        "        found = True\r\n",
        "        dataset = ws.datasets[key] \r\n",
        "        print(\"Found\")\r\n",
        "\r\n",
        "if not found:\r\n",
        "        # Create AML Dataset and register it into Workspace\r\n",
        "        example_data = 'https://raw.githubusercontent.com/BMUHAMMDI/nd00333-capstone/master/starter_file/heart_failure_clinical_records_dataset.csv'\r\n",
        "        dataset = Dataset.Tabular.from_delimited_files(example_data)        \r\n",
        "        #Register Dataset in Workspace\r\n",
        "        dataset = dataset.register(workspace=ws,\r\n",
        "                                   name=key)\r\n",
        "\r\n",
        "\r\n",
        "df = dataset.to_pandas_dataframe()\r\n",
        "df.describe()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 39,
          "data": {
            "text/plain": "         age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\ncount 299.00   299.00                    299.00    299.00             299.00   \nmean   60.83     0.43                    581.84      0.42              38.08   \nstd    11.89     0.50                    970.29      0.49              11.83   \nmin    40.00     0.00                     23.00      0.00              14.00   \n25%    51.00     0.00                    116.50      0.00              30.00   \n50%    60.00     0.00                    250.00      0.00              38.00   \n75%    70.00     1.00                    582.00      1.00              45.00   \nmax    95.00     1.00                   7861.00      1.00              80.00   \n\n       high_blood_pressure  platelets  serum_creatinine  serum_sodium    sex  \\\ncount               299.00     299.00            299.00        299.00 299.00   \nmean                  0.35  263358.03              1.39        136.63   0.65   \nstd                   0.48   97804.24              1.03          4.41   0.48   \nmin                   0.00   25100.00              0.50        113.00   0.00   \n25%                   0.00  212500.00              0.90        134.00   0.00   \n50%                   0.00  262000.00              1.10        137.00   1.00   \n75%                   1.00  303500.00              1.40        140.00   1.00   \nmax                   1.00  850000.00              9.40        148.00   1.00   \n\n       smoking   time  DEATH_EVENT  \ncount   299.00 299.00       299.00  \nmean      0.32 130.26         0.32  \nstd       0.47  77.61         0.47  \nmin       0.00   4.00         0.00  \n25%       0.00  73.00         0.00  \n50%       0.00 115.00         0.00  \n75%       1.00 203.00         1.00  \nmax       1.00 285.00         1.00  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>age</th>\n      <th>anaemia</th>\n      <th>creatinine_phosphokinase</th>\n      <th>diabetes</th>\n      <th>ejection_fraction</th>\n      <th>high_blood_pressure</th>\n      <th>platelets</th>\n      <th>serum_creatinine</th>\n      <th>serum_sodium</th>\n      <th>sex</th>\n      <th>smoking</th>\n      <th>time</th>\n      <th>DEATH_EVENT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n      <td>299.00</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>60.83</td>\n      <td>0.43</td>\n      <td>581.84</td>\n      <td>0.42</td>\n      <td>38.08</td>\n      <td>0.35</td>\n      <td>263358.03</td>\n      <td>1.39</td>\n      <td>136.63</td>\n      <td>0.65</td>\n      <td>0.32</td>\n      <td>130.26</td>\n      <td>0.32</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>11.89</td>\n      <td>0.50</td>\n      <td>970.29</td>\n      <td>0.49</td>\n      <td>11.83</td>\n      <td>0.48</td>\n      <td>97804.24</td>\n      <td>1.03</td>\n      <td>4.41</td>\n      <td>0.48</td>\n      <td>0.47</td>\n      <td>77.61</td>\n      <td>0.47</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>40.00</td>\n      <td>0.00</td>\n      <td>23.00</td>\n      <td>0.00</td>\n      <td>14.00</td>\n      <td>0.00</td>\n      <td>25100.00</td>\n      <td>0.50</td>\n      <td>113.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>4.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>51.00</td>\n      <td>0.00</td>\n      <td>116.50</td>\n      <td>0.00</td>\n      <td>30.00</td>\n      <td>0.00</td>\n      <td>212500.00</td>\n      <td>0.90</td>\n      <td>134.00</td>\n      <td>0.00</td>\n      <td>0.00</td>\n      <td>73.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>60.00</td>\n      <td>0.00</td>\n      <td>250.00</td>\n      <td>0.00</td>\n      <td>38.00</td>\n      <td>0.00</td>\n      <td>262000.00</td>\n      <td>1.10</td>\n      <td>137.00</td>\n      <td>1.00</td>\n      <td>0.00</td>\n      <td>115.00</td>\n      <td>0.00</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>70.00</td>\n      <td>1.00</td>\n      <td>582.00</td>\n      <td>1.00</td>\n      <td>45.00</td>\n      <td>1.00</td>\n      <td>303500.00</td>\n      <td>1.40</td>\n      <td>140.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>203.00</td>\n      <td>1.00</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>95.00</td>\n      <td>1.00</td>\n      <td>7861.00</td>\n      <td>1.00</td>\n      <td>80.00</td>\n      <td>1.00</td>\n      <td>850000.00</td>\n      <td>9.40</td>\n      <td>148.00</td>\n      <td>1.00</td>\n      <td>1.00</td>\n      <td>285.00</td>\n      <td>1.00</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 39,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610484594124
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "training_data, test_data = train_test_split(df, test_size=0.20)"
      ],
      "outputs": [],
      "execution_count": 40,
      "metadata": {
        "gather": {
          "logged": 1610484604684
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## AutoML Configuration\n",
        "\n",
        "TODO: Explain why you chose the automl settings and cofiguration you used below."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.data.dataset_factory import TabularDatasetFactory\r\n",
        "if not os.path.isdir(\"data\"):\r\n",
        "    os.mkdir(\"data\")\r\n",
        "\r\n",
        "pd.DataFrame(training_data).to_csv(\"data/train_data.csv\", index=False)\r\n",
        "ds=ws.get_default_datastore()\r\n",
        "ds.upload(src_dir='./data', target_path='HeartDataset', overwrite=True,show_progress=True)\r\n",
        "train_data=TabularDatasetFactory.from_delimited_files(path=ds.path('HeartDataset/train_data.csv'))\r\n",
        "print(train_data.to_pandas_dataframe())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploading an estimated of 2 files\n",
            "Uploading ./data/test_ds.csv\n",
            "Uploaded ./data/test_ds.csv, 1 files out of an estimated total of 2\n",
            "Uploading ./data/train_data.csv\n",
            "Uploaded ./data/train_data.csv, 2 files out of an estimated total of 2\n",
            "Uploaded 2 files\n",
            "      age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
            "0   70.00        1                        69         1                 50   \n",
            "1   65.00        0                       167         0                 30   \n",
            "2   60.00        0                        59         0                 25   \n",
            "3   66.00        1                        68         1                 38   \n",
            "4   70.00        0                      2695         1                 40   \n",
            "..    ...      ...                       ...       ...                ...   \n",
            "234 55.00        0                       582         1                 35   \n",
            "235 70.00        0                       835         0                 35   \n",
            "236 64.00        1                        62         0                 60   \n",
            "237 53.00        1                        91         0                 20   \n",
            "238 58.00        0                       144         1                 38   \n",
            "\n",
            "     high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
            "0                      1  351000.00              1.00           134    0   \n",
            "1                      0  259000.00              0.80           138    0   \n",
            "2                      1  212000.00              3.50           136    1   \n",
            "3                      1  162000.00              1.00           136    0   \n",
            "4                      0  241000.00              1.00           137    1   \n",
            "..                   ...        ...               ...           ...  ...   \n",
            "234                    1  371000.00              0.70           140    0   \n",
            "235                    1  305000.00              0.80           133    0   \n",
            "236                    0  309000.00              1.50           135    0   \n",
            "237                    1  418000.00              1.40           139    0   \n",
            "238                    1  327000.00              0.70           142    0   \n",
            "\n",
            "     smoking  time  DEATH_EVENT  \n",
            "0          0    44            1  \n",
            "1          0   186            0  \n",
            "2          1   187            0  \n",
            "3          0    95            0  \n",
            "4          0   247            0  \n",
            "..       ...   ...          ...  \n",
            "234        0   197            0  \n",
            "235        0   145            0  \n",
            "236        0   174            0  \n",
            "237        0    43            1  \n",
            "238        0    83            0  \n",
            "\n",
            "[239 rows x 13 columns]\n"
          ]
        }
      ],
      "execution_count": 41,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610484622340
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Put your automl settings here\n",
        "automl_settings = {\"experiment_timeout_minutes\": 25,\n",
        "                    \"max_concurrent_iterations\":4,                     \n",
        "}\n",
        "\n",
        "# TODO: Put your automl config here\n",
        "automl_config = AutoMLConfig(  \n",
        "    task='classification',\n",
        "    compute_target='cpu-cluster',\n",
        "    primary_metric = 'accuracy',\n",
        "    training_data= train_data,\n",
        "    label_column_name ='DEATH_EVENT',\n",
        "    enable_onnx_compatible_models=True,\n",
        "    featurization='auto',\n",
        "    enable_early_stopping= True,\n",
        "    **automl_settings\n",
        ")"
      ],
      "outputs": [],
      "execution_count": 45,
      "metadata": {
        "gather": {
          "logged": 1610488412306
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Submit your experiment\n",
        "remote_run = experiment.submit(config=automl_config, show_output=True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running on remote.\n",
            "No run_configuration provided, running on cpu-cluster with default configuration\n",
            "Running on remote compute: cpu-cluster\n",
            "Parent Run ID: AutoML_840c15d7-cc55-44fd-8bc0-4507609ca357\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Cross validation\n",
            "STATUS:       DONE\n",
            "DESCRIPTION:  Each iteration of the trained model was validated through cross-validation.\n",
            "              \n",
            "DETAILS:      \n",
            "+---------------------------------+\n",
            "|Number of folds                  |\n",
            "+=================================+\n",
            "|10                               |\n",
            "+---------------------------------+\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:05:39       0.8449    0.8449\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:07:33       0.8283    0.8449\n",
            "         2   MinMaxScaler RandomForest                      0:07:59       0.8201    0.8449\n",
            "         3   MinMaxScaler RandomForest                      0:08:05       0.8159    0.8449\n",
            "         4   MinMaxScaler RandomForest                      0:05:29       0.8370    0.8449\n"
          ]
        }
      ],
      "execution_count": 46,
      "metadata": {
        "gather": {
          "logged": 1610488099423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Details\n",
        "\n",
        "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
        "\n",
        "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "RunDetails(remote_run).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610482227429
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Model\n",
        "\n",
        "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
        "\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "best_automl_run,fitted_model = remote_run.get_output()\r\n",
        "print(best_automl_run)\r\n",
        "print(fitted_model)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610482237953
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_automl_run"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610482247999
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_automl_run.get_metrics()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610482256898
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Save the best model\r\n",
        "best_automl_run,onnx_model =remote_run.get_output(return_onnx_model=True)\r\n",
        "OnnxConverter.save_onnx_model(onnx_model,file_path=\"./automl_model.onnx\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610482315686
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Deployment\n",
        "\n",
        "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
        "\n",
        "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#Register the best automl model,\r\n",
        "automl_model =remote_run.register_model(model_name = 'automl_best_model')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1610482322148
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_file_name ='inference/sscore.py'\r\n",
        "best_automl_run.download_file('outputs/scoring_file_v_1_0_0.py','inference/sscore.py')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610482325516
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_config = InferenceConfig(entry_script=script_file_name, environment=best_automl_run.get_environment())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610482332025
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Local Deployment\r\n",
        "from azureml.core.webservice import LocalWebservice\r\n",
        "local_config = LocalWebservice.deploy_configuration(port=9001)\r\n",
        "local_service = Model.deploy(ws, \"test\", [automl_model], inference_config, local_config)\r\n",
        "local_service.wait_for_deployment(show_output=True)\r\n",
        "\r\n",
        "#Set up the deployment_config as webservice\r\n",
        "aci_config = AciWebservice.deploy_configuration(cpu_cores=1, memory_gb=1, enable_app_insights=True)\r\n",
        "\r\n",
        "#Deploy the model\r\n",
        "service = Model.deploy(\r\n",
        "    workspace = ws,\r\n",
        "    name = \"heart-failure-model\",\r\n",
        "    models = [automl_model],\r\n",
        "    inference_config = inference_config,\r\n",
        "    deployment_config = aci_config, overwrite=True)\r\n",
        "\r\n",
        "#wait until deployment is complete\r\n",
        "service.wait_for_deployment(show_output = True)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610482717446
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Scoring uri:\" , service.scoring_uri)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610483949123
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, send a request to the web service you deployed to test it."
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598431657736
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(test_data).to_csv(\"data/test_ds.csv\", index=False)\r\n",
        "test_ds=pd.read_csv(\"data/test_ds.csv\")\r\n",
        "#test_ds.drop(test_ds.columns[0],axis=1,inplace=True)\r\n",
        "test_ds.drop(test_ds.columns[12],axis=1,inplace=True)\r\n",
        "test_ds.info()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610483231171
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data= test_ds[0:3].to_json(orient=\"table\", index=False)\r\n",
        "test_sample=json.dumps(json.loads(data) ,indent=4)\r\n",
        "output=service.run(test_sample)\r\n",
        "print(output)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610307994044
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scoring_uri = 'http://f1db25ef-d00c-4743-9ca4-02c25f14a67f.southcentralus.azurecontainer.io/score'\r\n",
        "headers = {'Content-Type':'application/json'}\r\n",
        "\r\n",
        "test_data = json.dumps({'data':[{\r\n",
        "    'age':75,\r\n",
        "    'anaemia':0,\r\n",
        "    'creatinine_phosphokinase':582,\r\n",
        "    'diabetes':0,\r\n",
        "    'ejection_fraction':20,\r\n",
        "    'high_blood_pressure':1,\r\n",
        "    'platelets':265000,\r\n",
        "    'serum_creatinine':1.9,\r\n",
        "    'serum_sodium':130,\r\n",
        "    'sex':1,\r\n",
        "    'smoking':0,\r\n",
        "    'time':4}\r\n",
        "    ]\r\n",
        "        })\r\n",
        "\r\n",
        "test_data2 = json.dumps({'data':[{\r\n",
        "    'age':40,\r\n",
        "    'anaemia':0,\r\n",
        "    'creatinine_phosphokinase':321,\r\n",
        "    'diabetes':0,\r\n",
        "    'ejection_fraction':35,\r\n",
        "    'high_blood_pressure':0,\r\n",
        "    'platelets':265000,\r\n",
        "    'serum_creatinine':1,\r\n",
        "    'serum_sodium':130,\r\n",
        "    'sex':1,\r\n",
        "    'smoking':0,\r\n",
        "    'time':198}\r\n",
        "    ]\r\n",
        "        })\r\n",
        "\r\n",
        "\r\n",
        "response = requests.post(scoring_uri, data=test_data2, headers=headers)\r\n",
        "\r\n",
        "print(\"Result:\",response.text)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610483997143
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "TODO: In the cell below, print the logs of the web service and delete the service"
      ],
      "metadata": {
        "collapsed": true,
        "gather": {
          "logged": 1598432765711
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Print the webservice logs\r\n",
        "print(service.get_logs())"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1610484513249
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Delete the service\r\n",
        "service.delete()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python3"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}